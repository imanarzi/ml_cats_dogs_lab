{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression: cat or dog?\n",
    "In this lab you will teach computer to distinguish between images of cats and dogs using Logistic Regression. \n",
    "The input dataset consists of 10,000 images manually labeled as ''cats'' and ''dogs''. The original dataset was downloaded from kaggle. \n",
    "\n",
    "Download the entire [folder](https://drive.google.com/file/d/1V4pAtGy7VOJQlxM3g8gyDee8h5k7VTSF/view?usp=sharing)  with images and unzip it into your local directory containing input files for this course. Then set the path below to point to this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../../data_ml_2020/cat_dog_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Import all the required libraries. \n",
    "If you get an import error on `keras`, run one of the next 2 cells to install `keras` in the current Jupyter kernel, and then rerun the import cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3a71bf2efc57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from PIL import Image\n",
    "from keras import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: / "
     ]
    }
   ],
   "source": [
    "# Install a conda package (with all its dependencies) in the current Jupyter kernel\n",
    "# this will work if you have a clean installation of anaconda\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively - install keras package and its dependencies using pip\n",
    "import sys\n",
    "!pip install --upgrade tensorflow\n",
    "!pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Load images\n",
    "First check if the path to the directory is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "os.chdir(cwd)\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next create two lists and fill them with the paths to the corresponding images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cats_files = []\n",
    "train_path_cats = data_dir +\"/training_set/cats/\"\n",
    "for path in os.listdir(train_path_cats):\n",
    "    if '.jpg' in path:\n",
    "        train_cats_files.append(os.path.join(train_path_cats, path))\n",
    "        \n",
    "train_dogs_files = []\n",
    "train_path_dogs = data_dir +\"/training_set/dogs/\"\n",
    "for path in os.listdir(train_path_dogs):\n",
    "    if '.jpg' in path:\n",
    "        train_dogs_files.append(os.path.join(train_path_dogs, path))\n",
    "        \n",
    "len(train_cats_files), len(train_dogs_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the paths to each image in the training set.\n",
    "We need to convert each image into a numpy array. For this we use the preprocessing module in the `keras` library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 200\n",
    "sample_dog_file = train_dogs_files[k]\n",
    "img = preprocessing.image.load_img(sample_dog_file, target_size=(64, 64))\n",
    "img_array = preprocessing.image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.uint8(img_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array.shape\n",
    "# print(img_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is represented as a $64*64$ matrix of pixels, and for each pixel we have values of Red, Green, and Blue (RGB). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Images to numpy arrays\n",
    "Now we create training sets for cats and for dogs and then concatenate 2 sets into a single `X_train` dataset of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image dimensions: using 32x32 pixels just for speed\n",
    "d = 32\n",
    "X_train_orig = np.zeros((8000, d, d, 3), dtype='float32')\n",
    "for i in range(4000):    \n",
    "    path = train_cats_files[i]\n",
    "    img = preprocessing.image.load_img(path, target_size=(d, d))\n",
    "    X_train_orig[i] = preprocessing.image.img_to_array(img)\n",
    "\n",
    "for i in range(4000,8000):    \n",
    "    path = train_dogs_files[i-4000]\n",
    "    img = preprocessing.image.load_img(path, target_size=(d, d))\n",
    "    X_train_orig[i] = preprocessing.image.img_to_array(img)    \n",
    "\n",
    "X_train_orig.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Flatten 3D image arrays\n",
    "Our model requires each object to be a 1D vector of features -\n",
    "we need to flatten our 3D image arrays.\n",
    "\n",
    "After reshaping we will have,\n",
    "$d*d*3$ features as a single array for each picture in the training set (8000 pics),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_orig.reshape(8000,-1)\n",
    "print(X_train[0])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Create class labels\n",
    "Now we need to create the corresponding class label vectors. We will mark the cats as class 1, and the dogs as class 0 (not cats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_orig = np.ones((4000,)) # 1 - 4000 are cat pictures so our label is 1\n",
    "Y_train_orig = np.concatenate((Y_train_orig, np.zeros((4000,)))) # 4000 - 8000 are dog pictures so our label is 0\n",
    "Y_train = Y_train_orig.reshape(-1)\n",
    "print(\"At position 3 should be a cat:\", Y_train[3])\n",
    "print(\"At position 4002 should be a dog:\", Y_train[4002])\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Build the model\n",
    "We are using the `LogisticRegression` class from `sklearn` package.\n",
    "<ul>\n",
    "<li>The <code>random_state</code> parameter tells to shuffle the samples, so the classifier does not see all the cats first, and then the dogs. Specifying  the `random_state` value ensures that the algorithm starts from the same random seed and produces reproducible results.</li> \n",
    "<li>The <code>max_iter</code> parameter tells algorithm to stop even if it did not reach the thrreshold for convergence yet.</li>\n",
    "    <li>In the <code>solver</code> parameter you can specify the algorithm which you want to use.</li>\n",
    "</ul>\n",
    "\n",
    "You can read more about the parameters of  `LogisticRegression` model [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "algorithms = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'] # default='lbfgs'\n",
    "logreg = linear_model.LogisticRegression(solver=algorithms[1], random_state = 42, max_iter= 1000)\n",
    "logreg.fit (X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score of the logistic regression classifier is simply a percentage of correctly predicted data points. This measure is called the **accuracy** of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = logreg.score(X_train, Y_train)\n",
    "print(\"train accuracy: {} \".format(acc_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lab Task 1: Model evaluation  \\[60%\\]\n",
    "Obviously, we are much more interested to see how our model performs on the test data. To create a test set, repeat steps 1.2-1.5 for the test_set folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cats_files = []\n",
    "test_path_cats = data_dir +\"/test_set/cats/\"\n",
    "# <Your code here>\n",
    "\n",
    "test_dogs_files = []\n",
    "test_path_dogs = data_dir +\"/test_set/dogs/\"\n",
    "# <Your code here>\n",
    "\n",
    "len(test_cats_files), len(test_dogs_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Images to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_orig = np.zeros((2000, d, d, 3), dtype='float32')  \n",
    "# <Your code here>\n",
    "X_test_orig.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Flatten 3D image arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test # <Your code here>\n",
    "print(X_test[0])\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Create class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test #<Your code here>\n",
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Accuracy for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test = logreg.score(X_test, Y_test)\n",
    "print(\"test accuracy: {} \".format(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Improve the model\n",
    "If the predictive power of the classifier is too low, try to improve the model. Below are some suggestions for improving it. Rerun the model after each modification and see if the accuracy of prediction is improved. \n",
    "\n",
    "Carefully record the results of your experiments in a separate markdown cell.\n",
    "\n",
    "<ol>\n",
    "    <li>Increase value of $d$ (image dimensions) to 64.</li>\n",
    "    <li>Normalize values in pixel arrays by dividing each value by 255 (max RGB value).</li>\n",
    "    <li>Use a different model-fitting algorithm.</li>\n",
    "    <li>Modify default parameters of <code>LogisticRegression</code> class.</li>\n",
    "    <li>$\\ldots$</li>\n",
    "</ol>\n",
    "\n",
    "You can stop once you have a good accuracy for the test set (no less than 0.60)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7. Predict random cats\n",
    "Find a random image of a cat and another of a dog, and test your model to predict it. Follow all the steps to convert two images into an array of features and then call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_new = [[...], [...]]\n",
    "Y_new = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit your images with your lab, and specify which prediction did you obtain for each image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8. Save model to file\n",
    "When you are happy with the performance of your model and want to use it to identify cats in the future, save it to file using pickle. An example how to save the model and then reload it can be found [here](\n",
    "https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/).\n",
    "\n",
    "Test that you can save the model and then load it in the cell below. Put your saved model to your google drive folder and provide the link to it in your notebook submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Lab Task 2: Support Vector Machines \\[40%\\]\n",
    "First, watch the [video](https://www.youtube.com/watch?v=efR1C6CvhmE&vl=en) about another classifier: Support Vector Machine (SVM).\n",
    "\n",
    "Next, perform the cat/dog image classification learning using SVM.\n",
    "Learn about the parameters of the sklearn SVC class [here](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC # \"Support vector classifier\"\n",
    "svm = SVC(kernel='rbf', C=1E3)\n",
    "#<Your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM is a more powerful classifier than logistic regression. Try to achieve a better accuracy by playing with the algorithm parameters. Report the final values in a new markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, in a newly added markdown cell briefly explain how do you understand the difference between the logistic regression and SVM learning algorithms. Pay a special attention to how these algorithms treat a decision boundary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2020 Marina Barsky. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
